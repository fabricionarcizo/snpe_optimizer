{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48ba2a1",
   "metadata": {},
   "source": [
    "# Model Zoo Notebook\n",
    "\n",
    "This notebook demonstrates how to load a COCO-pretrained YOLO-NAS S model and a hagRID-pretrained YOLO 11 model, and export them to ONNX format using PyTorch, SuperGradients, and Ultralytics and to TensorFlow using [onnx2tf](https://github.com/PINTO0309/onnx2tf).\n",
    "\n",
    "**Important:**  \n",
    "This notebook must be executed first before running any other notebooks in this project. It prepares the modela and exports them for further use.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Build and start the Docker Compose environment** as described in the project documentation.\n",
    "2. **Access this notebook** in your browser at:  \n",
    "    [http://127.0.0.1:8889/notebooks/model_zoo.ipynb](http://127.0.0.1:8889/notebooks/model_zoo.ipynb)\n",
    "3. **Run all cells** in order to prepare the models for downstream tasks.\n",
    "\n",
    "Make sure to follow these steps to ensure the environment and model are set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf30e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31 19:51:03] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is logged into /root/sg_logs/console.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31 19:51:04] INFO - font_manager.py - generated new fontManager\n",
      "2025-05-31 19:51:04.635433: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-31 19:51:04.678632: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748721064.700340     450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748721064.706589     450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748721064.743897     450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721064.743921     450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721064.743922     450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721064.743923     450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-31 19:51:04.749193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries.\n",
    "from typing import List\n",
    "\n",
    "import onnx\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from onnx import helper, TensorProto\n",
    "from super_gradients.common.object_names import Models\n",
    "from super_gradients.training import models\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189e0db",
   "metadata": {},
   "source": [
    "## Exporting YOLO-NAS S Model to ONNX\n",
    "\n",
    "The following code cell loads a COCO-pretrained YOLO-NAS S model using SuperGradients, prepares it for ONNX export, and saves the exported model to the `./models/yolo_nas_s.onnx` path. The process includes:\n",
    "\n",
    "- Loading the pretrained model and setting it to evaluation mode.\n",
    "- Preparing the model for conversion with a specified input size.\n",
    "- Creating a dummy input tensor to simulate a real input.\n",
    "- Defining input and output names for the ONNX graph.\n",
    "- Exporting the model to ONNX format using `torch.onnx.export`.\n",
    "\n",
    "This ONNX model can then be used for inference in other frameworks or deployment environments that support ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99683984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31 19:51:07] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
      " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
      " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
      "[2025-05-31 19:51:07] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
      "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
      "By downloading the pre-trained weight files you agree to comply with these terms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://sg-hub-nv.s3.amazonaws.com/models/yolo_nas_s_coco.pth\" to /root/.cache/torch/hub/checkpoints/yolo_nas_s_coco.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73.1M/73.1M [00:06<00:00, 11.2MB/s]\n",
      "[2025-05-31 19:51:14] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is valid!\n"
     ]
    }
   ],
   "source": [
    "# Load a COCO-pretrained YOLO-NAS S model.\n",
    "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")\n",
    "model.eval()\n",
    "\n",
    "# Prepare the model for ONNX conversion.\n",
    "model.prep_model_for_conversion(input_size=[1, 3, 320, 320])\n",
    "\n",
    "# Define a dummy input tensor with the expected shape.\n",
    "dummy_input = torch.randn([1, 3, 320, 320], device=\"cpu\")\n",
    "\n",
    "# Specify the input and output names for the ONNX model.\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output_bboxes\", \"output_classes\"]\n",
    "\n",
    "# Export the model to ONNX format.\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"/models/yolo_nas_s.onnx\",\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "# Validate the ONNX model.\n",
    "model = onnx.load(\"/models/yolo_nas_s.onnx\")\n",
    "onnx.checker.check_model(model)\n",
    "print(\"Model is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc31aed",
   "metadata": {},
   "source": [
    "## ONNX Model Graph Transformation Utility\n",
    "\n",
    "The following code cell defines a utility function, `transform_io_and_prune_node`, which modifies an ONNX model's computation graph. This function enables advanced manipulation of ONNX models, including:\n",
    "\n",
    "- Renaming the model's input tensor.\n",
    "- Removing all existing outputs and creating new output chains using Transpose and Identity nodes.\n",
    "- Assigning new names to the outputs and connecting them to specified internal tensors.\n",
    "- Removing a specific node (e.g., a Concat node) from the model by its name.\n",
    "\n",
    "This utility is useful for customizing ONNX models for downstream tasks, such as adapting the model's input/output interface or pruning unnecessary nodes before deployment. The function takes paths to the input and output ONNX models, new input/output names, internal tensor names for output chaining, and the name of the node to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb3afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_io_and_prune_node(\n",
    "    model_path: str, output_path: str,\n",
    "    new_input_name: str,\n",
    "    new_output_names: List,\n",
    "    internal_tensor_names: List,\n",
    "    remove_node_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Transforms the input and output of an ONNX model, renaming the input,\n",
    "    removing all outputs, and creating a new output chain with Transpose and\n",
    "    Identity nodes. Also removes a specified node from the model.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the input ONNX model.\n",
    "        output_path (str): Path to save the modified ONNX model.\n",
    "        new_input_name (str): New name for the input tensor.\n",
    "        new_output_names (List[str]): List of new names for the output tensors.\n",
    "        internal_tensor_names (List[str]): List of internal tensor names to be\n",
    "            used in the new output chain.\n",
    "        remove_node_name (str): Name of the node to be removed from the model.\n",
    "    \"\"\"\n",
    "    model = onnx.load(model_path)\n",
    "\n",
    "    # Step 1: Rename input.\n",
    "    old_input_name = model.graph.input[0].name\n",
    "    model.graph.input[0].name = new_input_name\n",
    "    for node in model.graph.node:\n",
    "        node.input[:] = [\n",
    "            new_input_name if i == old_input_name else i for i in node.input\n",
    "        ]\n",
    "\n",
    "    # Step 2: Remove all outputs.\n",
    "    del model.graph.output[:]\n",
    "\n",
    "    # Step 3: Build new output chain: Transpose → Identity → output.\n",
    "    transpose_axes = [\n",
    "        [0, 2, 1],  # Same for both outputs.\n",
    "        [0, 2, 1],  # Same for both outputs.\n",
    "    ]\n",
    "    output_shapes = [\n",
    "        [1, 8400,  4],  # For output_bboxes, for example\n",
    "        [1, 8400, 34],  # For output_classes, for example\n",
    "    ]\n",
    "\n",
    "    new_nodes = []\n",
    "    for i, (new_name, internal_name) in enumerate(\n",
    "        zip(new_output_names, internal_tensor_names)\n",
    "    ):\n",
    "        transpose_name = f\"{new_name}_transposed\"\n",
    "\n",
    "        # Transpose node.\n",
    "        transpose_node = helper.make_node(\n",
    "            \"Transpose\",\n",
    "            inputs=[internal_name],\n",
    "            outputs=[transpose_name],\n",
    "            perm=transpose_axes[i],\n",
    "            name=f\"Transpose_{new_name}\"\n",
    "        )\n",
    "\n",
    "        # Identity node to assign output name.\n",
    "        identity_node = helper.make_node(\n",
    "            \"Identity\",\n",
    "            inputs=[transpose_name],\n",
    "            outputs=[new_name],\n",
    "            name=f\"Identity_{new_name}\"\n",
    "        )\n",
    "\n",
    "        # Output metadata.\n",
    "        output_info = helper.make_tensor_value_info(\n",
    "            new_name,\n",
    "            TensorProto.FLOAT,\n",
    "            output_shapes[i]\n",
    "        )\n",
    "\n",
    "        # Append to graph.\n",
    "        new_nodes.extend([transpose_node, identity_node])\n",
    "        model.graph.output.append(output_info)\n",
    "\n",
    "    # Step 4: Remove the Concat node by name.\n",
    "    original_nodes = [\n",
    "        node for node in model.graph.node if node.name != remove_node_name\n",
    "    ]\n",
    "\n",
    "    # Step 5: Replace node list with cleaned + new output nodes.\n",
    "    model.graph.ClearField(\"node\")\n",
    "    model.graph.node.extend(original_nodes + new_nodes)\n",
    "\n",
    "    # Save model.\n",
    "    onnx.save(model, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07507b68",
   "metadata": {},
   "source": [
    "## Downloading the hagRID YOLO 11 Model Weights\n",
    "\n",
    "The following code cell downloads the pretrained YOLO 11 model weights from Hugging Face and saves them to the `/models` directory. These weights are required for loading the hagRID-pretrained YOLO model and exporting it to ONNX format in subsequent steps. Make sure the download completes successfully before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f768729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/best.pt     100%[===================>]  15.34M  9.64MB/s    in 1.6s    \n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/testdummyvt/hagRIDv2_gesture_det_models/resolve/main/yolo11n_10GB/train/weights/best.pt -q --show-progress -O /models/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a946685",
   "metadata": {},
   "source": [
    "## Exporting and Transforming the hagRID YOLO 11 Model\n",
    "\n",
    "The following code cell performs several key steps to prepare the hagRID-pretrained YOLO 11 model for downstream use:\n",
    "\n",
    "- **Load the YOLO 11 model** using the downloaded weights.\n",
    "- **Export the model to ONNX format** with the appropriate opset version.\n",
    "- **Load the exported ONNX model** for further processing.\n",
    "- **Transform the ONNX model** by:\n",
    "    - Renaming the input and outputs to standardized names.\n",
    "    - Creating new output chains for bounding boxes and class predictions.\n",
    "    - Removing an unnecessary node from the computation graph.\n",
    "- **Clean up** by deleting the original `.pt` and intermediate ONNX files to conserve disk space.\n",
    "\n",
    "This process ensures the exported ONNX model is optimized and ready for integration into other applications or inference pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194f23e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146 🚀 Python-3.10.16 torch-2.7.0+cu126 CPU (13th Gen Intel Core(TM) i9-13950HX)\n",
      "💡 ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLO11n summary (fused): 100 layers, 2,588,782 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/models/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 38, 8400) (15.3 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim>=0.1.53'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxslim>=0.1.53\n",
      "  Downloading onnxslim-0.1.55-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: onnx in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from onnxslim>=0.1.53) (1.15.0)\n",
      "Requirement already satisfied: sympy in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from onnxslim>=0.1.53) (1.14.0)\n",
      "Requirement already satisfied: packaging in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from onnxslim>=0.1.53) (25.0)\n",
      "Requirement already satisfied: numpy in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from onnx->onnxslim>=0.1.53) (1.23.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from onnx->onnxslim>=0.1.53) (3.20.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/.miniconda3/envs/model-zoo/lib/python3.10/site-packages (from sympy->onnxslim>=0.1.53) (1.3.0)\n",
      "Downloading onnxslim-0.1.55-py3-none-any.whl (146 kB)\n",
      "Installing collected packages: onnxslim\n",
      "Successfully installed onnxslim-0.1.55\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 1.7s\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 11...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.55...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.3s, saved as '/models/best.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (2.6s)\n",
      "Results saved to \u001b[1m/models\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/models/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/models/best.onnx imgsz=640 data=/mnt/batch/tasks/shared/LS_root/mounts/clusters/t4-two/data/hagRIDv2_512px_10GB/yolo_format/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Model is valid!\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = YOLO(\"/models/best.pt\")\n",
    "\n",
    "# Export to ONNX.\n",
    "model.export(format=\"onnx\", opset=11)\n",
    "\n",
    "# Transform the model by renaming inputs, outputs, and pruning a node.\n",
    "transform_io_and_prune_node(\n",
    "    model_path=\"/models/best.onnx\",\n",
    "    output_path=\"/models/yolo_hagRID.onnx\",\n",
    "    new_input_name=\"input\",\n",
    "    new_output_names=[\n",
    "        \"output_bboxes\",\n",
    "        \"output_classes\"\n",
    "    ],\n",
    "    internal_tensor_names=[\n",
    "        \"/model.23/Mul_2_output_0\",\n",
    "        \"/model.23/Sigmoid_output_0\"\n",
    "    ],\n",
    "    remove_node_name=\"/model.23/Concat_5\"\n",
    ")\n",
    "\n",
    "# Validate the ONNX model.\n",
    "model = onnx.load(\"/models/yolo_hagRID.onnx\")\n",
    "onnx.checker.check_model(model)\n",
    "print(\"Model is valid!\")\n",
    "\n",
    "# Delete the original .pt and ONNX models to save space.\n",
    "os.remove(\"/models/best.pt\")\n",
    "os.remove(\"/models/best.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176cee8",
   "metadata": {},
   "source": [
    "## Exporting YOLO-NAS S Model to TensorFlow\n",
    "\n",
    "To export the COCO-pretrained YOLO-NAS S model to TensorFlow format, follow these steps:\n",
    "\n",
    "1. **Ensure the ONNX model is available:**  \n",
    "    The YOLO-NAS S model should already be exported to ONNX format at `./models/yolo_nas_s.onnx` (see previous steps).\n",
    "\n",
    "2. **Use `onnx2tf` for conversion:**  \n",
    "    The `onnx2tf` tool can convert ONNX models to TensorFlow's SavedModel format.  \n",
    "    Run the following command in a notebook cell:\n",
    "\n",
    "    ```python\n",
    "    !zsh -c 'onnx2tf -i /models/yolo_nas_s.onnx -o /models/yolo_nas_s'\n",
    "    ```\n",
    "\n",
    "    - `-i` specifies the input ONNX model path.\n",
    "    - `-o` specifies the output directory for the TensorFlow SavedModel.\n",
    "\n",
    "3. **Result:**  \n",
    "    After running the command, the TensorFlow SavedModel will be saved in `./models/yolo_nas_s`.  \n",
    "    You can now use this model for inference or further processing in TensorFlow-based workflows.\n",
    "\n",
    "**Note:**  \n",
    "Make sure `onnx2tf` is installed in your environment. If not, install it using `pip install onnx2tf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c731c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748721085.919049     631 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748721085.921816     631 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748721085.929591     631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721085.929610     631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721085.929612     631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748721085.929613     631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add           │ 21             │ 21               │\n",
      "│ Cast          │ 3              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Concat        │ 20             │ \u001b[1;32m16              \u001b[0m │\n",
      "│ Constant      │ 242            │ \u001b[1;32m229             \u001b[0m │\n",
      "│ Conv          │ 101            │ 101              │\n",
      "│ ConvTranspose │ 2              │ 2                │\n",
      "│ Expand        │ 6              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ MaxPool       │ 3              │ 3                │\n",
      "│ Mul           │ 21             │ 21               │\n",
      "│ Relu          │ 92             │ 92               │\n",
      "│ Reshape       │ 9              │ \u001b[1;32m6               \u001b[0m │\n",
      "│ Sigmoid       │ 1              │ 1                │\n",
      "│ Softmax       │ 3              │ 3                │\n",
      "│ Split         │ 1              │ 1                │\n",
      "│ Squeeze       │ 3              │ 3                │\n",
      "│ Sub           │ 1              │ 1                │\n",
      "│ Transpose     │ 7              │ 7                │\n",
      "│ Unsqueeze     │ 6              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Model Size    │ 46.5MiB        │ 46.5MiB          │\n",
      "└───────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add           │ 21             │ 21               │\n",
      "│ Concat        │ 16             │ 16               │\n",
      "│ Constant      │ 229            │ 229              │\n",
      "│ Conv          │ 101            │ 101              │\n",
      "│ ConvTranspose │ 2              │ 2                │\n",
      "│ MaxPool       │ 3              │ 3                │\n",
      "│ Mul           │ 21             │ 21               │\n",
      "│ Relu          │ 92             │ 92               │\n",
      "│ Reshape       │ 6              │ 6                │\n",
      "│ Sigmoid       │ 1              │ 1                │\n",
      "│ Softmax       │ 3              │ 3                │\n",
      "│ Split         │ 1              │ 1                │\n",
      "│ Squeeze       │ 3              │ 3                │\n",
      "│ Sub           │ 1              │ 1                │\n",
      "│ Transpose     │ 7              │ 7                │\n",
      "│ Model Size    │ 46.5MiB        │ 46.5MiB          │\n",
      "└───────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add           │ 21             │ 21               │\n",
      "│ Concat        │ 16             │ 16               │\n",
      "│ Constant      │ 229            │ 229              │\n",
      "│ Conv          │ 101            │ 101              │\n",
      "│ ConvTranspose │ 2              │ 2                │\n",
      "│ MaxPool       │ 3              │ 3                │\n",
      "│ Mul           │ 21             │ 21               │\n",
      "│ Relu          │ 92             │ 92               │\n",
      "│ Reshape       │ 6              │ 6                │\n",
      "│ Sigmoid       │ 1              │ 1                │\n",
      "│ Softmax       │ 3              │ 3                │\n",
      "│ Split         │ 1              │ 1                │\n",
      "│ Squeeze       │ 3              │ 3                │\n",
      "│ Sub           │ 1              │ 1                │\n",
      "│ Transpose     │ 7              │ 7                │\n",
      "│ Model Size    │ 46.5MiB        │ 46.5MiB          │\n",
      "└───────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 320, 320] \u001b[32mdtype\u001b[0m: float32\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stem/conv/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 320, 320] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1109 \u001b[36mshape\u001b[0m: [48, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1110 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stem/conv/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 322, 322, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stem/conv/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stem/conv/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stem/conv/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 160, 160, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/downsample/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stem/conv/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 160, 160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1112 \u001b[36mshape\u001b[0m: [96, 48, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1113 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1/Pad:0 \u001b[34mshape\u001b[0m: (1, 162, 162, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/downsample/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1115 \u001b[36mshape\u001b[0m: [32, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1116 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1130 \u001b[36mshape\u001b[0m: [32, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1131 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1118 \u001b[36mshape\u001b[0m: [32, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1119 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage1.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1121 \u001b[36mshape\u001b[0m: [32, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1122 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1124 \u001b[36mshape\u001b[0m: [32, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1125 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage1.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1127 \u001b[36mshape\u001b[0m: [32, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1128 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage1/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 64, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1133 \u001b[36mshape\u001b[0m: [96, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1134 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage1/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage1/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/downsample/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1136 \u001b[36mshape\u001b[0m: [192, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1137 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (1, 82, 82, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_skip2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage1/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1277 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1278 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_skip2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/downsample/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_skip2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_skip2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_skip2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 80, 80, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1139 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1140 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1160 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1161 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/downsample/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_skip2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 80, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1280 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1281 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (1, 82, 82, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/downsample/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1142 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1143 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage2.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_9/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1145 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1146 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_9/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1148 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1149 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage2.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_13/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1151 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1152 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m45 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m46 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_13/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m47 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1154 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1155 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m48 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage2.blocks.bottlenecks.2.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_17/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m49 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m50 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1157 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1158 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m51 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m52 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_17/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m53 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/bottlenecks/bottlenecks.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage2/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m54 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1163 \u001b[36mshape\u001b[0m: [192, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1164 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m55 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage2/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m56 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/downsample/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1166 \u001b[36mshape\u001b[0m: [384, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1167 \u001b[36mshape\u001b[0m: [384] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4/Pad:0 \u001b[34mshape\u001b[0m: (1, 42, 42, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (384,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m57 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_skip2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1241 \u001b[36mshape\u001b[0m: [192, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1242 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_skip2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m58 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_skip1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1274 \u001b[36mshape\u001b[0m: [96, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1275 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_skip1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m59 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/downsample/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m60 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_skip2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_skip2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_skip2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m61 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_skip1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_skip1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_skip1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m62 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1169 \u001b[36mshape\u001b[0m: [96, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1170 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m63 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1202 \u001b[36mshape\u001b[0m: [96, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1203 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m64 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/downsample/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_skip2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1244 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1245 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_5/Pad:0 \u001b[34mshape\u001b[0m: (1, 42, 42, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m65 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m66 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m67 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/downsample/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/downsample/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m68 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1172 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1173 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m69 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage3.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_21/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m70 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_27/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m71 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1175 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1176 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_27/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m72 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m73 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_21/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m74 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1178 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1179 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m75 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage3.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_25/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m76 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m77 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1181 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1182 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m78 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_30/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m79 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_25/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_30/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m80 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1184 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1185 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m81 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage3.blocks.bottlenecks.2.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_29/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m82 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m83 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1187 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1188 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m84 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m85 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_29/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m86 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1190 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1191 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m87 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage3.blocks.bottlenecks.3.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_33/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m88 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_33/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m89 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1193 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1194 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_33/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m90 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m91 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_33/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m92 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1196 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1197 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m93 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage3.blocks.bottlenecks.4.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_37/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m94 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m95 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1199 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1200 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m96 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_36/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m97 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_37/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_36/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m98 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/bottlenecks/bottlenecks.4/Add_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage3/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_2/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m99 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1205 \u001b[36mshape\u001b[0m: [384, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1206 \u001b[36mshape\u001b[0m: [384] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_2/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (384,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m100 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage3/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m101 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/downsample/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1208 \u001b[36mshape\u001b[0m: [768, 384, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1209 \u001b[36mshape\u001b[0m: [768] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_6/Pad:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 384, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (768,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m102 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_skip1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1238 \u001b[36mshape\u001b[0m: [192, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1239 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_skip1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m103 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/downsample/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/downsample/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m104 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_skip1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_skip1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_skip1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_39/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m105 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1211 \u001b[36mshape\u001b[0m: [192, 768, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1212 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 768, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m106 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/downsample/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1226 \u001b[36mshape\u001b[0m: [192, 768, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1227 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 768, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m107 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m108 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m109 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1214 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1215 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m110 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage4.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_41/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m111 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_42/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m112 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1217 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1218 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_42/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m113 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m114 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_41/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m115 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1220 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1221 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m116 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: backbone.stage4.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_45/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m117 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m118 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1223 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1224 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m119 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_45/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m120 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_45/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_45/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m121 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/stage4/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_3/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m122 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1229 \u001b[36mshape\u001b[0m: [768, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1230 \u001b[36mshape\u001b[0m: [768] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_3/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (768,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m123 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/stage4/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/stage4/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m124 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/cv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/stage4/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1232 \u001b[36mshape\u001b[0m: [384, 768, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1233 \u001b[36mshape\u001b[0m: [384] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 768, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (384,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m125 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/cv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m126 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/m.0/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/m.0/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [5, 5] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [2, 2, 2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m127 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/m.1/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/m.1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [9, 9] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [4, 4, 4, 4] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_1/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m128 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/m.2/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/m.2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [13, 13] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [6, 6, 6, 6] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_2/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m129 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /backbone/context_module/m.0/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /backbone/context_module/m.1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: /backbone/context_module/m.2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1536, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_1/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.nn.pool_2/max_pool:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_4/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 1536) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m130 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/cv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1536, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1235 \u001b[36mshape\u001b[0m: [768, 1536, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1236 \u001b[36mshape\u001b[0m: [768] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_4/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 1536) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1536, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (768,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m131 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /backbone/context_module/cv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /backbone/context_module/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m132 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/conv/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /backbone/context_module/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 768, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1247 \u001b[36mshape\u001b[0m: [192, 768, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1248 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 768) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 768, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m133 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/conv/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m134 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvTranspose\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/upsample/ConvTranspose\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.neck1.upsample.weight \u001b[36mshape\u001b[0m: [192, 192, 2, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.neck1.upsample.bias \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/upsample/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: conv2d_transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \u001b[34mshape\u001b[0m: (2, 2, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 20, 20, 192] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.8.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_74/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m135 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/upsample/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/reduce_skip1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /neck/neck1/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 576, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_74/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_39/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_5/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 576) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m136 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_after_concat/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 576, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1250 \u001b[36mshape\u001b[0m: [192, 576, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1251 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_after_concat/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_5/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 576) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 576, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m137 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/reduce_after_concat/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_after_concat/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m138 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1253 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1254 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m139 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1268 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1269 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m140 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m141 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m142 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1256 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1257 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m143 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck1.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_49/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m144 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m145 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1259 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1260 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_53/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m146 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_54/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m147 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_49/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_54/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m148 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1262 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1263 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m149 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck1.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_53/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m150 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_55/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m151 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1265 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1266 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_55/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m152 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_56/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m153 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_53/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_56/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_85/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m154 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_85/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_52/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_6/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m155 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1271 \u001b[36mshape\u001b[0m: [192, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1272 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_6/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_86/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m156 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck1/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck1/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_86/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_57/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m157 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/conv/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck1/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1283 \u001b[36mshape\u001b[0m: [96, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1284 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_57/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_87/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m158 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/conv/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_87/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_58/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m159 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ConvTranspose\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/upsample/ConvTranspose\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: neck.neck2.upsample.weight \u001b[36mshape\u001b[0m: [96, 96, 2, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: neck.neck2.upsample.bias \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/upsample/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: conv2d_transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_58/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \u001b[34mshape\u001b[0m: (2, 2, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 40, 40, 96] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.8.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m160 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/upsample/ConvTranspose_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/reduce_skip1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /neck/neck2/downsample/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 288, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_7/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 288) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m161 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_after_concat/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 288, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1286 \u001b[36mshape\u001b[0m: [96, 288, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1287 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_after_concat/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_7/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 288) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 288, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m162 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/reduce_after_concat/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_after_concat/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_59/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m163 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1289 \u001b[36mshape\u001b[0m: [48, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1290 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_59/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m164 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/reduce_after_concat/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1304 \u001b[36mshape\u001b[0m: [48, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1305 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_59/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_91/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m165 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_60/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m166 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_91/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_61/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m167 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1292 \u001b[36mshape\u001b[0m: [48, 48, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1293 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_60/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_92/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m168 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck2.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_60/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_57/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m169 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_92/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_62/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m170 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1295 \u001b[36mshape\u001b[0m: [48, 48, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1296 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_62/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_93/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m171 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_93/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_63/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m172 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_57/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_63/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m173 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1298 \u001b[36mshape\u001b[0m: [48, 48, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1299 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_96/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m174 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck2.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_61/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m175 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_96/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_64/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m176 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv1/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1301 \u001b[36mshape\u001b[0m: [48, 48, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1302 \u001b[36mshape\u001b[0m: [48] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_64/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 48, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (48,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_97/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m177 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/rbr_reparam/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_97/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_65/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m178 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/cv2/nonlinearity/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_61/Mul:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_65/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_99/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m179 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 48, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_99/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_61/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 48) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_8/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m180 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1307 \u001b[36mshape\u001b[0m: [96, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1308 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_8/concat:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m181 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck2/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_66/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m182 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/conv/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1310 \u001b[36mshape\u001b[0m: [96, 96, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1311 \u001b[36mshape\u001b[0m: [96] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_7/Pad:0 \u001b[34mshape\u001b[0m: (1, 42, 42, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 96, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (96,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m183 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head1/stem/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck2/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1358 \u001b[36mshape\u001b[0m: [64, 96, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1359 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_66/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 96, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_102/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m184 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/conv/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_67/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m185 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head1/stem/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_102/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_68/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m186 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck2/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 96, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_67/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_58/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 96) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_9/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m187 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1361 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1362 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_68/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_103/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m188 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1364 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1365 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_68/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m189 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1313 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1314 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_9/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_105/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m190 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1328 \u001b[36mshape\u001b[0m: [64, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1329 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_9/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_106/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m191 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_103/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_69/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m192 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_70/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m193 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_105/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_71/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m194 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_106/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_72/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m195 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head1/cls_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head1.cls_pred.weight \u001b[36mshape\u001b[0m: [80, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head1.cls_pred.bias \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_69/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_107/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m196 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head1/reg_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head1.reg_pred.weight \u001b[36mshape\u001b[0m: [68, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head1.reg_pred.bias \u001b[36mshape\u001b[0m: [68] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head1/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_70/Relu:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (68,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_108/Add:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m197 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1316 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1317 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_71/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_109/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m198 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck3.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck3/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_71/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_65/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m199 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 1600] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_18/transpose:0 \u001b[34mshape\u001b[0m: (1, 68, 40, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 4, 17, 1600] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 1600) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m200 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head1/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 40, 40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_2_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_1_output_0 \u001b[36mshape\u001b[0m: [1, 80, 1600] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_23/transpose:0 \u001b[34mshape\u001b[0m: (1, 80, 40, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 80, 1600] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_5/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 1600) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m201 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_109/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_73/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m202 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 1600] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1600, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 1600) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 1, 3, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_26/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 1600, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m203 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1319 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1320 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_73/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m204 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Softmax\u001b[35m onnx_op_name\u001b[0m: /heads/Softmax\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1600, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Softmax_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1600, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: softmax_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.logits\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_26/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 1600, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax/wa/heads/Softmax:0 \u001b[34mshape\u001b[0m: (1, 4, 1600, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m205 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_74/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m206 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Softmax_output_0 \u001b[36mshape\u001b[0m: [1, 4, 1600, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_1_output_0 \u001b[36mshape\u001b[0m: [1, 17, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax/wa/heads/Softmax:0 \u001b[34mshape\u001b[0m: (1, 4, 1600, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 3, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_27/transpose:0 \u001b[34mshape\u001b[0m: (1, 17, 1600, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m207 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_65/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_74/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m208 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_1_output_0 \u001b[36mshape\u001b[0m: [1, 17, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_1_output_0 \u001b[36mshape\u001b[0m: [1, 17, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_29/transpose:0 \u001b[34mshape\u001b[0m: (1, 1600, 4, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 17, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_77/convolution:0 \u001b[34mshape\u001b[0m: (1, 1600, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m209 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1322 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1323 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_113/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m210 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck3.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_69/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m211 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Squeeze\u001b[35m onnx_op_name\u001b[0m: /heads/Squeeze\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 1, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Squeeze_output_0 \u001b[36mshape\u001b[0m: [1, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: squeeze_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_77/convolution:0 \u001b[34mshape\u001b[0m: (1, 1600, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_5/wa/heads/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 1600, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m212 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_113/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_75/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m213 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1325 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1326 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_75/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_114/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m214 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_114/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_76/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m215 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_69/Mul:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_76/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_116/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m216 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck3/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_116/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_72/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_10/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m217 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1331 \u001b[36mshape\u001b[0m: [192, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1332 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_10/concat:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_117/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m218 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck3/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_117/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_77/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m219 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/conv/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1334 \u001b[36mshape\u001b[0m: [192, 192, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1335 \u001b[36mshape\u001b[0m: [192] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_8/Pad:0 \u001b[34mshape\u001b[0m: (1, 22, 22, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 192, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (192,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_118/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m220 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head2/stem/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck3/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1367 \u001b[36mshape\u001b[0m: [128, 192, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1368 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_77/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 192, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_119/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m221 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/conv/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/conv/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_118/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_78/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m222 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head2/stem/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_119/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_79/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m223 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck1/conv/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 192, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_78/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 192) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_11/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m224 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1370 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1371 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_79/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_120/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m225 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1373 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1374 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_79/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_121/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m226 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1337 \u001b[36mshape\u001b[0m: [64, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1338 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_11/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_122/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m227 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1352 \u001b[36mshape\u001b[0m: [64, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1353 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_11/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_123/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m228 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_120/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_80/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m229 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_121/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_81/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m230 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/conv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_122/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_82/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m231 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/conv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_123/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_83/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m232 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head2/cls_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head2.cls_pred.weight \u001b[36mshape\u001b[0m: [80, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head2.cls_pred.bias \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_80/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_124/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m233 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head2/reg_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head2.reg_pred.weight \u001b[36mshape\u001b[0m: [68, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head2.reg_pred.bias \u001b[36mshape\u001b[0m: [68] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head2/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_81/Relu:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (68,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_125/Add:0 \u001b[34mshape\u001b[0m: (1, 20, 20, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m234 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1340 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1341 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_82/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_126/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m235 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck4.blocks.bottlenecks.0.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck4/blocks/conv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_82/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_73/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m236 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_3_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 400] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_33/transpose:0 \u001b[34mshape\u001b[0m: (1, 68, 20, 20) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 4, 17, 400] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_8/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 400) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m237 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape_3\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head2/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 20, 20] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_5_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_3_output_0 \u001b[36mshape\u001b[0m: [1, 80, 400] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_38/transpose:0 \u001b[34mshape\u001b[0m: (1, 80, 20, 20) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 80, 400] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_11/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 400) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m238 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_126/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m239 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Reshape_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 400] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 400, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_8/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 400) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 1, 3, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_41/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 400, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m240 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1343 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1344 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_84/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_127/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m241 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Softmax\u001b[35m onnx_op_name\u001b[0m: /heads/Softmax_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 400, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Softmax_1_output_0 \u001b[36mshape\u001b[0m: [1, 4, 400, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: softmax_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.logits\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_41/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 400, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_1/wa/heads/Softmax_1:0 \u001b[34mshape\u001b[0m: (1, 4, 400, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m242 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_127/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_85/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m243 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_3\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Softmax_1_output_0 \u001b[36mshape\u001b[0m: [1, 4, 400, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_3_output_0 \u001b[36mshape\u001b[0m: [1, 17, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_1/wa/heads/Softmax_1:0 \u001b[34mshape\u001b[0m: (1, 4, 400, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 3, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_42/transpose:0 \u001b[34mshape\u001b[0m: (1, 17, 400, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m244 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_73/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_85/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m245 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/Conv_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_3_output_0 \u001b[36mshape\u001b[0m: [1, 17, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_1_output_0 \u001b[36mshape\u001b[0m: (1, 17, 1, 1) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Conv_1_output_0 \u001b[36mshape\u001b[0m: [1, 1, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_44/transpose:0 \u001b[34mshape\u001b[0m: (1, 400, 4, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 17, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_91/convolution:0 \u001b[34mshape\u001b[0m: (1, 400, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m246 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1346 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1347 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_130/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m247 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: neck.neck4.blocks.bottlenecks.1.alpha \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.0/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_77/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m248 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Squeeze\u001b[35m onnx_op_name\u001b[0m: /heads/Squeeze_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Conv_1_output_0 \u001b[36mshape\u001b[0m: [1, 1, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Squeeze_1_output_0 \u001b[36mshape\u001b[0m: [1, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: squeeze_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_91/convolution:0 \u001b[34mshape\u001b[0m: (1, 400, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_11/wa/heads/Squeeze_1:0 \u001b[34mshape\u001b[0m: (1, 400, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m249 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_130/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_86/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m250 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv1/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1349 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1350 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_86/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_131/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m251 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_131/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_87/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m252 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/cv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_77/Mul:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_87/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_133/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m253 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/bottlenecks/bottlenecks.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /neck/neck4/blocks/conv2/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_133/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_83/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_12/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m254 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv3/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 128, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1355 \u001b[36mshape\u001b[0m: [384, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1356 \u001b[36mshape\u001b[0m: [384] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_12/concat:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (384,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_134/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m255 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /neck/neck4/blocks/conv3/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/conv3/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /neck/neck4/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_134/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_88/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m256 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head3/stem/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /neck/neck4/blocks/conv3/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 384, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1376 \u001b[36mshape\u001b[0m: [256, 384, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1377 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_88/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 384) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 384, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m257 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head3/stem/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/stem/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_89/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m258 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1379 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1380 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_89/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_136/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m259 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/conv/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/stem/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_1382 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_1383 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_89/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m260 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_136/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_90/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m261 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/act/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/conv/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_91/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m262 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head3/cls_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/cls_convs/cls_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head3.cls_pred.weight \u001b[36mshape\u001b[0m: [80, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head3.cls_pred.bias \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_90/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_138/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m263 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/head3/reg_pred/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/reg_convs/reg_convs.0/seq/act/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: heads.head3.reg_pred.weight \u001b[36mshape\u001b[0m: [68, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: heads.head3.reg_pred.bias \u001b[36mshape\u001b[0m: [68] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/head3/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_91/Relu:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (68,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_139/Add:0 \u001b[34mshape\u001b[0m: (1, 10, 10, 68) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m264 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape_4\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/reg_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 68, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_6_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_48/transpose:0 \u001b[34mshape\u001b[0m: (1, 68, 10, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 4, 17, 100] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_14/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m265 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /heads/Reshape_5\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/head3/cls_pred/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 10, 10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_8_output_0 \u001b[36mshape\u001b[0m: [3] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Reshape_5_output_0 \u001b[36mshape\u001b[0m: [1, 80, 100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_53/transpose:0 \u001b[34mshape\u001b[0m: (1, 80, 10, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 80, 100] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_17/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m266 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_4\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Reshape_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 17, 100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 100, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_14/Reshape:0 \u001b[34mshape\u001b[0m: (1, 4, 17, 100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 1, 3, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_56/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 100, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m267 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /heads/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Reshape_1_output_0 \u001b[36mshape\u001b[0m: [1, 80, 1600] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Reshape_3_output_0 \u001b[36mshape\u001b[0m: [1, 80, 400] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /heads/Reshape_5_output_0 \u001b[36mshape\u001b[0m: [1, 80, 100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 80, 2100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_5/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 1600) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_11/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 400) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_17/Reshape:0 \u001b[34mshape\u001b[0m: (1, 80, 100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_13/concat:0 \u001b[34mshape\u001b[0m: (1, 80, 2100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m268 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Softmax\u001b[35m onnx_op_name\u001b[0m: /heads/Softmax_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_4_output_0 \u001b[36mshape\u001b[0m: [1, 4, 100, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Softmax_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 100, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: softmax_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.logits\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_56/transpose:0 \u001b[34mshape\u001b[0m: (1, 4, 100, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_2/wa/heads/Softmax_2:0 \u001b[34mshape\u001b[0m: (1, 4, 100, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m269 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 80, 2100] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_6_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_13/concat:0 \u001b[34mshape\u001b[0m: (1, 80, 2100) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_57/transpose:0 \u001b[34mshape\u001b[0m: (1, 2100, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m270 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /heads/Transpose_5\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Softmax_2_output_0 \u001b[36mshape\u001b[0m: [1, 4, 100, 17] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Transpose_5_output_0 \u001b[36mshape\u001b[0m: [1, 17, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax_2/wa/heads/Softmax_2:0 \u001b[34mshape\u001b[0m: (1, 4, 100, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [0, 3, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_58/transpose:0 \u001b[34mshape\u001b[0m: (1, 17, 100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m271 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: /heads/Sigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_6_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output_classes \u001b[36mshape\u001b[0m: [1, 2100, 80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_57/transpose:0 \u001b[34mshape\u001b[0m: (1, 2100, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid/Sigmoid:0 \u001b[34mshape\u001b[0m: (1, 2100, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m272 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /heads/Conv_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Transpose_5_output_0 \u001b[36mshape\u001b[0m: [1, 17, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_1_output_0 \u001b[36mshape\u001b[0m: (1, 17, 1, 1) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Conv_2_output_0 \u001b[36mshape\u001b[0m: [1, 1, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_59/transpose:0 \u001b[34mshape\u001b[0m: (1, 100, 4, 17) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 17, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_100/convolution:0 \u001b[34mshape\u001b[0m: (1, 100, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m273 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Squeeze\u001b[35m onnx_op_name\u001b[0m: /heads/Squeeze_2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Conv_2_output_0 \u001b[36mshape\u001b[0m: [1, 1, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Squeeze_2_output_0 \u001b[36mshape\u001b[0m: [1, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: squeeze_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_100/convolution:0 \u001b[34mshape\u001b[0m: (1, 100, 4, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [3] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_18/wa/heads/Squeeze_2:0 \u001b[34mshape\u001b[0m: (1, 100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m274 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /heads/Concat_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Squeeze_output_0 \u001b[36mshape\u001b[0m: [1, 1600, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Squeeze_1_output_0 \u001b[36mshape\u001b[0m: [1, 400, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: /heads/Squeeze_2_output_0 \u001b[36mshape\u001b[0m: [1, 100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_5/wa/heads/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 1600, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_11/wa/heads/Squeeze_1:0 \u001b[34mshape\u001b[0m: (1, 400, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_18/wa/heads/Squeeze_2:0 \u001b[34mshape\u001b[0m: (1, 100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.axis\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_14/concat:0 \u001b[34mshape\u001b[0m: (1, 2100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m275 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Split\u001b[35m onnx_op_name\u001b[0m: /heads/Split\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Concat_1_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Split_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.2\u001b[0m: /heads/Split_output_1 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: split\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.value\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_14/concat:0 \u001b[34mshape\u001b[0m: (1, 2100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.num_or_size_splits\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.num\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:1 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m276 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sub\u001b[35m onnx_op_name\u001b[0m: /heads/Sub\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Concat_5_output_0 \u001b[36mshape\u001b[0m: [2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Split_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: subtract\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mshape\u001b[0m: (2100, 2) \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m277 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /heads/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Split_output_1 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Concat_5_output_0 \u001b[36mshape\u001b[0m: (2100, 2) \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Add_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.split/split:1 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_140/Add:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m278 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /heads/Concat_6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Sub_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Add_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 2] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /heads/Concat_6_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.subtract/Sub:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_140/Add:0 \u001b[34mshape\u001b[0m: (1, 2100, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 2 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_17/concat:0 \u001b[34mshape\u001b[0m: (1, 2100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m279 / 279\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /heads/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /heads/Concat_6_output_0 \u001b[36mshape\u001b[0m: [1, 2100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /heads/Constant_21_output_0 \u001b[36mshape\u001b[0m: [2100, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output_bboxes \u001b[36mshape\u001b[0m: [1, 2100, 4] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_17/concat:0 \u001b[34mshape\u001b[0m: (1, 2100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 2100, 1) \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_83/Mul:0 \u001b[34mshape\u001b[0m: (1, 2100, 4) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "Saved artifact at '/models/saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serving_default'\n",
      "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 320, 320, 3), dtype=tf.float32, name='input')\n",
      "Output Type:\n",
      "  List[TensorSpec(shape=(1, 2100, 4), dtype=tf.float32, name=None), TensorSpec(shape=(1, 2100, 80), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  139948954041360: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948954041008: TensorSpec(shape=(3, 3, 3, 48), dtype=tf.float32, name=None)\n",
      "  139948954225296: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948954238144: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948954237792: TensorSpec(shape=(3, 3, 48, 96), dtype=tf.float32, name=None)\n",
      "  139948954651456: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954662192: TensorSpec(shape=(1, 1, 96, 32), dtype=tf.float32, name=None)\n",
      "  139948954662720: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948954690912: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139948954693376: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948964492768: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139948964492240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948954697248: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948964485024: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139948983797712: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948954030272: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
      "  139948954662368: TensorSpec(shape=(1, 1, 96, 32), dtype=tf.float32, name=None)\n",
      "  139948964488896: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948954684752: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
      "  139948954028688: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948988374832: TensorSpec(shape=(1, 1, 64, 96), dtype=tf.float32, name=None)\n",
      "  139948988377824: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948988315984: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948988315632: TensorSpec(shape=(3, 3, 96, 192), dtype=tf.float32, name=None)\n",
      "  139948988370080: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948988295024: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948988297488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988523872: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948988526160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988498512: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948988505904: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988501152: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948988506784: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948988487056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988497088: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948983669104: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988497616: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948983668752: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948983680720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988494272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948988288160: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948983503680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988300304: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948988524400: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948983510544: TensorSpec(shape=(1, 1, 128, 192), dtype=tf.float32, name=None)\n",
      "  139948983930544: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948983941808: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948983941456: TensorSpec(shape=(3, 3, 192, 384), dtype=tf.float32, name=None)\n",
      "  139948983942864: TensorSpec(shape=(384,), dtype=tf.float32, name=None)\n",
      "  139948983957312: TensorSpec(shape=(1, 1, 384, 96), dtype=tf.float32, name=None)\n",
      "  139948983783968: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948983794704: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954081712: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954781296: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954785872: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954091216: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948983785200: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954080304: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954849120: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954854576: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954850000: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948954857392: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954916592: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948965069392: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948965075552: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948954913248: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948965079776: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948965082592: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948964902544: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948965301232: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948964900960: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948954855984: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948954853168: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948965201344: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948983781680: TensorSpec(shape=(1, 1, 384, 96), dtype=tf.float32, name=None)\n",
      "  139948965206624: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948983786608: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948965314256: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948965208736: TensorSpec(shape=(1, 1, 192, 384), dtype=tf.float32, name=None)\n",
      "  139948965020768: TensorSpec(shape=(384,), dtype=tf.float32, name=None)\n",
      "  139948965034496: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948965034144: TensorSpec(shape=(3, 3, 384, 768), dtype=tf.float32, name=None)\n",
      "  139948965035552: TensorSpec(shape=(768,), dtype=tf.float32, name=None)\n",
      "  139948986528192: TensorSpec(shape=(1, 1, 768, 192), dtype=tf.float32, name=None)\n",
      "  139948986530656: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986515872: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948986607296: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986665088: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948986670720: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986613456: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948986606944: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948964904128: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986750880: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948986597440: TensorSpec(shape=(1, 1, 768, 192), dtype=tf.float32, name=None)\n",
      "  139948986756160: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986598320: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948986749296: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948986827344: TensorSpec(shape=(1, 1, 384, 768), dtype=tf.float32, name=None)\n",
      "  139948986828224: TensorSpec(shape=(768,), dtype=tf.float32, name=None)\n",
      "  139948986927936: TensorSpec(shape=(1, 1, 768, 384), dtype=tf.float32, name=None)\n",
      "  139948986928464: TensorSpec(shape=(384,), dtype=tf.float32, name=None)\n",
      "  139948986760384: TensorSpec(shape=(1, 1, 1536, 768), dtype=tf.float32, name=None)\n",
      "  139948983945520: TensorSpec(shape=(1, 1, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948987040864: TensorSpec(shape=(768,), dtype=tf.float32, name=None)\n",
      "  139948983944112: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948987052128: TensorSpec(shape=(1, 1, 768, 192), dtype=tf.float32, name=None)\n",
      "  139948983792768: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948987052480: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948983786432: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948965035376: TensorSpec(shape=(1, 1, 384, 192), dtype=tf.float32, name=None)\n",
      "  139948983793472: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948965024464: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948987079440: TensorSpec(shape=(2, 2, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948987042448: TensorSpec(shape=(1, 1, 576, 192), dtype=tf.float32, name=None)\n",
      "  139948987054064: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948987085072: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948987085600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987082256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948987212096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987237472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948987242576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987219488: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948987240464: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948987251024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987348096: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948987085776: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948987451872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987088416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948987346512: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948987465072: TensorSpec(shape=(1, 1, 128, 192), dtype=tf.float32, name=None)\n",
      "  139948988310704: TensorSpec(shape=(1, 1, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948987455568: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948988288336: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948985477152: TensorSpec(shape=(1, 1, 192, 96), dtype=tf.float32, name=None)\n",
      "  139948988373600: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948985477680: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948988298544: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948983943760: TensorSpec(shape=(1, 1, 192, 96), dtype=tf.float32, name=None)\n",
      "  139948988515424: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948983952032: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948985479616: TensorSpec(shape=(2, 2, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948987340528: TensorSpec(shape=(1, 1, 288, 96), dtype=tf.float32, name=None)\n",
      "  139948987459440: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948985554144: TensorSpec(shape=(1, 1, 96, 48), dtype=tf.float32, name=None)\n",
      "  139948985554672: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985566656: TensorSpec(shape=(3, 3, 48, 48), dtype=tf.float32, name=None)\n",
      "  139948985569120: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985577568: TensorSpec(shape=(3, 3, 48, 48), dtype=tf.float32, name=None)\n",
      "  139948985571408: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985575984: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948985639936: TensorSpec(shape=(3, 3, 48, 48), dtype=tf.float32, name=None)\n",
      "  139948985633952: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985768544: TensorSpec(shape=(3, 3, 48, 48), dtype=tf.float32, name=None)\n",
      "  139948985553792: TensorSpec(shape=(1, 1, 96, 48), dtype=tf.float32, name=None)\n",
      "  139948985774704: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985560304: TensorSpec(shape=(48,), dtype=tf.float32, name=None)\n",
      "  139948985770128: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948985772768: TensorSpec(shape=(1, 1, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948985812592: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948985932032: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948985931680: TensorSpec(shape=(3, 3, 96, 96), dtype=tf.float32, name=None)\n",
      "  139948985817696: TensorSpec(shape=(96,), dtype=tf.float32, name=None)\n",
      "  139948985991408: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948985997568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948986036672: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948986039312: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948986196640: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948986108560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948986038432: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948984536752: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948984568992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984638576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948985997216: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
      "  139948984641040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948985999680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984443200: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948984644560: TensorSpec(shape=(1, 1, 128, 192), dtype=tf.float32, name=None)\n",
      "  139948984580432: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948984675568: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
      "  139948984675216: TensorSpec(shape=(3, 3, 192, 192), dtype=tf.float32, name=None)\n",
      "  139948984676624: TensorSpec(shape=(192,), dtype=tf.float32, name=None)\n",
      "  139948984776688: TensorSpec(shape=(1, 1, 384, 64), dtype=tf.float32, name=None)\n",
      "  139948984765248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984904592: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948984976832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984831664: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948985069664: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984984400: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948984990032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948985247424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948985352256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948984832720: TensorSpec(shape=(1, 1, 384, 64), dtype=tf.float32, name=None)\n",
      "  139948985354720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948984837296: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948985167440: TensorSpec(shape=(1, 1, 1, 1), dtype=tf.float32, name=None)\n",
      "  139948985357008: TensorSpec(shape=(1, 1, 128, 384), dtype=tf.float32, name=None)\n",
      "  139948985360000: TensorSpec(shape=(384,), dtype=tf.float32, name=None)\n",
      "  139948973124848: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
      "  139948984679088: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
      "  139948985821392: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
      "  139948973125376: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139948984680144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139948985580736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948973165376: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  139948984772112: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139948985935728: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948973168896: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139948984828320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139948985938368: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948973262096: TensorSpec(shape=(1, 1, 256, 68), dtype=tf.float32, name=None)\n",
      "  139948984902480: TensorSpec(shape=(1, 1, 128, 68), dtype=tf.float32, name=None)\n",
      "  139948986030864: TensorSpec(shape=(1, 1, 64, 68), dtype=tf.float32, name=None)\n",
      "  139948973265616: TensorSpec(shape=(68,), dtype=tf.float32, name=None)\n",
      "  139948984904768: TensorSpec(shape=(68,), dtype=tf.float32, name=None)\n",
      "  139948986036496: TensorSpec(shape=(68,), dtype=tf.float32, name=None)\n",
      "  139948973126432: TensorSpec(shape=(3, 3, 256, 256), dtype=tf.float32, name=None)\n",
      "  139948984672224: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
      "  139948985926752: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
      "  139948973118688: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
      "  139948984643856: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
      "  139948985935024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
      "  139948973175584: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
      "  139948984895792: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
      "  139948986003552: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
      "  139948973344192: TensorSpec(shape=(1, 1, 17, 1), dtype=tf.float32, name=None)\n",
      "  139948984842400: TensorSpec(shape=(1, 1, 17, 1), dtype=tf.float32, name=None)\n",
      "  139948984548544: TensorSpec(shape=(1, 1, 17, 1), dtype=tf.float32, name=None)\n",
      "  139948973178048: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  139948984901424: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  139948986031040: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
      "  139948973502208: TensorSpec(shape=(2100, 2), dtype=tf.float32, name=None)\n",
      "  139948973581488: TensorSpec(shape=(1, 2100, 2), dtype=tf.float32, name=None)\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "I0000 00:00:1748721094.901221     631 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748721094.901336     631 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1748721095.694220     631 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1748721095.694247     631 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "I0000 00:00:1748721096.569958     631 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "I0000 00:00:1748721096.570058     631 single_machine.cc:374] Starting new session\n",
      "W0000 00:00:1748721097.112047     631 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1748721097.112070     631 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!zsh -c 'onnx2tf -i /models/yolo_nas_s.onnx -o /models/yolo_nas_s'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e399f5",
   "metadata": {},
   "source": [
    "## Notebook Complete\n",
    "\n",
    "You have now successfully prepared and exported both the COCO-pretrained YOLO-NAS S model and the hagRID-pretrained YOLO 11 model to ONNX format. These models are now ready for use in downstream tasks, such as inference, benchmarking, or integration into deployment pipelines.\n",
    "\n",
    "If you encounter any issues or need to re-run the setup, simply restart the notebook and execute all cells in order.\n",
    "\n",
    "For further information, refer to the project documentation or explore the exported ONNX models in the `/models` directory.\n",
    "\n",
    "---\n",
    "**Next Steps:**\n",
    "- Use the exported ONNX models in your inference or deployment workflows.\n",
    "- Explore other notebooks in this project for additional model processing and evaluation tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
